{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5108daa-0a79-4780-a9d9-12f5ee4d078d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Obtaining dependency information for youtube-transcript-api from https://files.pythonhosted.org/packages/80/d4/be6fd091d29ae49d93813e598769e7ab453419a4de640e1755bf20911cce/youtube_transcript_api-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\crist\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2024.12.14)\n",
      "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "   ---------------------------------------- 0.0/622.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/622.3 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/622.3 kB 330.3 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 71.7/622.3 kB 491.5 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 133.1/622.3 kB 714.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 215.0/622.3 kB 935.2 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 297.0/622.3 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 378.9/622.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 440.3/622.3 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 522.2/622.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  614.4/622.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 622.3/622.3 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e892e3fd-db5c-4399-b40b-832db113d684",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\crist\\anaconda3\\lib\\site-packages (15.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3d0ffc-099f-4be8-8a5d-e85b2c298440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_video = 'https://www.youtube.com/watch?v=r3TpcHebtxM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd851686-e89a-4f1b-b6a6-c457564f3338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript downloaded successfully and saved as youtube_transcript.json.\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter\n",
    "import json\n",
    "\n",
    "# Function to extract the video ID from a full YouTube URL\n",
    "def get_video_id(youtube_url):\n",
    "    if \"watch?v=\" in youtube_url:\n",
    "        return youtube_url.split(\"watch?v=\")[1].split(\"&\")[0]\n",
    "    elif \"youtu.be/\" in youtube_url:\n",
    "        return youtube_url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL format.\")\n",
    "\n",
    "# Enter the YouTube video URL\n",
    "youtube_url = target_video\n",
    "\n",
    "try:\n",
    "    # Get the video ID\n",
    "    video_id = get_video_id(youtube_url)\n",
    "\n",
    "    # Fetch the transcript\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "    # Format and save as JSON\n",
    "    formatter = JSONFormatter()\n",
    "    json_formatted = formatter.format_transcript(transcript)\n",
    "\n",
    "    # Save transcript to a file\n",
    "    with open(\"youtube_transcript.json\", \"w\") as f:\n",
    "        f.write(json_formatted)\n",
    "        \n",
    "    print(\"Transcript downloaded successfully and saved as youtube_transcript.json.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438482bd-a32f-4e43-9090-1a5befde0791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey I'm Dave welcome to my shop I'm Dave\n",
      "plumber a retired software engineer from\n",
      "Microsoft going back to the MS DOS at\n",
      "Windows 95 days and today we're tackling\n",
      "a seismic shift in the world of\n",
      "technology the release of China's open\n",
      "source AI model deep seek R1 this\n",
      "development has been described as\n",
      "nothing less than a Sputnik Moment by\n",
      "Mark andreon and for good reason just as\n",
      "the launch of Sputnik challenged\n",
      "assumptions about American technological\n",
      "dominance in the 20th century deep SEC\n",
      "car1 is forcing a reckoning in the 21st\n",
      "for years many believed that the race\n",
      "for AI Supremacy was firmly in the hands\n",
      "of the established players like open Ai\n",
      "and anthropic but with this breakthrough\n",
      "a new competitor has not just entered\n",
      "the field they've also seriously\n",
      "outpaced expectations if you care about\n",
      "the future of AI Innovation and Global\n",
      "technological competition you'll want to\n",
      "understand what deep seek R1 is why it\n",
      "matters whether it's just a giant scop\n",
      "and what it means for the World At Large\n",
      "let's dive in to set the stage here's\n",
      "the part that really upset the industry\n",
      "and sent the stocks of companies like\n",
      "Nvidia and Microsoft reeling not only\n",
      "does deep seek R1 meet or exceed the\n",
      "performance of the best American AI\n",
      "models like open AI 01 they did it on\n",
      "the cheap reportedly for under $6\n",
      "million and when you compare that to the\n",
      "tens of billions already invested if not\n",
      "more here to achieve similar results not\n",
      "to mention the $500 billion discussion\n",
      "around Stargate it's cause for alarm\n",
      "because not only does China claimed to\n",
      "have done it cheaply but they reportedly\n",
      "did it without access to the latest of\n",
      "nvidia's chips if true it's akin to\n",
      "building a Ferrari in your garage out of\n",
      "spare Chevy parts and if you can throw\n",
      "together a Ferrari in your shop on your\n",
      "own and it's really just as good as a\n",
      "regular Ferrari what do you think that\n",
      "does to Ferrari prices so it's a little\n",
      "bit like that and just what is deep SE\n",
      "car1 it's a new language model designed\n",
      "to offer performance that punches above\n",
      "its weight trained on a smaller scale\n",
      "but still capable of answering questions\n",
      "generating text and understanding\n",
      "context and what sets it apart isn't\n",
      "just the capabilities but the way that\n",
      "it's been built deep seek is designed to\n",
      "be cheap efficient and surprisingly\n",
      "resourceful leveraging larger\n",
      "foundational AIS like open AI gp4 or\n",
      "meta llama as scaffolding to create\n",
      "something much larger let's unpack that\n",
      "because at its core deep seek R1 is a\n",
      "distilled language model when you train\n",
      "a large AI model you end up with\n",
      "something massive hundreds of billions\n",
      "if not a trillion parameters consuming\n",
      "terabytes of data and requiring a data\n",
      "centers worth of gpus just a function\n",
      "but what if you don't need all that\n",
      "power for most tasks and that's where\n",
      "the idea of distillation comes in you\n",
      "take a larger model like a gp4 or the\n",
      "671 billion parameter Behemoth R1 and\n",
      "you use it to train the smaller ones\n",
      "it's like a master Craftsman teaching an\n",
      "apprentice you don't need The Apprentice\n",
      "to know everything just enough to do the\n",
      "actual job really well deep seek R1\n",
      "takes this approach to an extreme by\n",
      "using larger models to guide its\n",
      "training deep seek creators have managed\n",
      "to compress the knowledge and reasoning\n",
      "capabilities of much bigger systems into\n",
      "something far smaller and more\n",
      "lightweight the result a model that\n",
      "doesn't need massive data centers to\n",
      "operate you can run the smaller variants\n",
      "on a decent consumer grade CPU or even a\n",
      "b laptop and that's a GameChanger but\n",
      "how does this work well it's a bit like\n",
      "teaching by example let's say you have a\n",
      "large model that knows everything about\n",
      "astrophysics Shakespeare and python\n",
      "coding and instead of trying to\n",
      "replicate that raw computational power\n",
      "deep seek R1 is trying to mimic the\n",
      "outputs of the larger model for a wide\n",
      "range of questions and scenarios by\n",
      "carefully selecting examples and iter\n",
      "ating over the training process you can\n",
      "teach the smaller model to produce\n",
      "similar answers without needing to store\n",
      "all that raw information itself it's\n",
      "kind of like copying the answers without\n",
      "the entire library and here's where it\n",
      "gets even more interesting because deep\n",
      "seek didn't just rely on a single large\n",
      "model for the process it used multiple\n",
      "AIS including some open source ones like\n",
      "meta llama to provide diverse\n",
      "perspectives and solutions during the\n",
      "training thinking of it assembling like\n",
      "a panel of experts to train one\n",
      "exceptionally bright student by\n",
      "combining insights from different\n",
      "architectures and data sets deep seek R1\n",
      "achieves a level of robustness and\n",
      "adaptability that's rare in such a small\n",
      "model it's too early to draw very many\n",
      "conclusions but the open- source nature\n",
      "of the model means that any biases or\n",
      "filters built into the model should be\n",
      "discoverable in the publicly available\n",
      "weights which is a fancy way of saying\n",
      "that it's hard to hide that stuff when\n",
      "the model is open source in fact one of\n",
      "my first tests was to ask deep seek what\n",
      "famous photo depicts a man standing in\n",
      "front of a line of Tanks it correctly\n",
      "answered the tonan Square protest tests\n",
      "the significance of the photo who took\n",
      "it and even the censorship issues\n",
      "surrounding it of course the online\n",
      "version of Deep seek may be completely\n",
      "different cuz I'm running it offline\n",
      "locally and who knows what version they\n",
      "get within China but the public version\n",
      "that you can download seems solid and\n",
      "reliable so why does all this matter\n",
      "well for one it dramatically lowers the\n",
      "barrier to entry for AI instead of\n",
      "requiring massive infrastructure in your\n",
      "own nuclear power plant to deploy a\n",
      "large language model you could\n",
      "potentially get by with a much smaller\n",
      "setup that's good news for smaller\n",
      "companies research Labs or even\n",
      "hobbyists looking to experiment with AI\n",
      "without breaking the bank in fact I'm\n",
      "running it on our AMD thread Ripper\n",
      "that's equipped with an Nvidia RTX 68\n",
      "GPU that has 48 GB of vram and I can run\n",
      "the very largest 671 billion parameter\n",
      "model and it still generates more than\n",
      "four tokens per second and even the 32\n",
      "billion version runs nicely on my\n",
      "MacBook Pro and the smaller ones run\n",
      "down to the Ora Nano for\n",
      "$249 but there's a catch building\n",
      "something on the cheap has some risks\n",
      "for starters smaller models often\n",
      "struggle with the bread and depth of\n",
      "knowledge that the larger ones have\n",
      "they're more prone to hallucinations\n",
      "generating confident but incorrect\n",
      "responses sometimes and they might not\n",
      "be as good at handling highly\n",
      "Specialized or nuanced queries\n",
      "additionally because these smaller\n",
      "models rely on training data from the\n",
      "larger ones they're only as good as\n",
      "their teachers so if there are errors or\n",
      "biases in the large models that they\n",
      "train on those issues can trickle down\n",
      "into the smaller ones and then there's\n",
      "the issue of scaling deep seeks\n",
      "efficiency is impressive but it also\n",
      "highlights the trade-offs involved by\n",
      "focusing on cost and accessibility deep\n",
      "seek R1 might not compete directly with\n",
      "the biggest players in term of Cutting\n",
      "Edge capabilities instead it carves out\n",
      "an important Niche for itself as a\n",
      "practical cost-effective alternative in\n",
      "some ways this approach reminds me a bit\n",
      "of the early days of personal Computing\n",
      "back then you had massive mainframes\n",
      "dominating the industry and then Along\n",
      "Came these scrappy little PCS that\n",
      "couldn't quite do everything but were\n",
      "good enough for a lot of the work fast\n",
      "forward a few decades in the PC\n",
      "revolutionized Computing deep seek might\n",
      "not be GPT 5 but it could pave the way\n",
      "for a more democratized AI landscape\n",
      "where Advanced tools aren't confined to\n",
      "a handful of tech Giants the\n",
      "implications here are huge imagine AI\n",
      "models tailored to specific Industries\n",
      "running on local hardware for privacy\n",
      "and control or even embedded in devices\n",
      "like smartphones and smart home hubs the\n",
      "idea of having your own personal AI\n",
      "assistant one that doesn't rely on a\n",
      "massive Cloud backend suddenly feels a\n",
      "lot more attainable of course the road\n",
      "ahead isn't without its challenges deep\n",
      "seek and models like it must prove that\n",
      "they can handle real world tasks\n",
      "reliably scale effectively and continue\n",
      "to innovate in a space dominated so far\n",
      "by much larger competitors but if\n",
      "there's one thing we've learned from the\n",
      "history of technology is that Innovation\n",
      "doesn't always come from the biggest\n",
      "players sometimes all it takes is a\n",
      "fresh perspective and a willingness or\n",
      "sometimes the necessity to do things\n",
      "differently deep SE car1 signals that\n",
      "China is not just a participant in the\n",
      "global AI race but a formidable\n",
      "competitor capable of producing Cutting\n",
      "Edge open source models for American AI\n",
      "companies like open AI Google deep minds\n",
      "and anthropic this creates a dual\n",
      "challenge maintaining technological\n",
      "leadership and justifying the price\n",
      "premium in the face of increasingly\n",
      "capable cost-effective Alternatives so\n",
      "what are the implications for American\n",
      "AI well open source models like deepsea\n",
      "car1 allow developers worldwide to\n",
      "innovate at lower cost this could\n",
      "undermine the competitive advantage of\n",
      "proprietary models particularly in areas\n",
      "like research and small to medium\n",
      "Enterprise adoption us companies that\n",
      "rely heavily on subscription or API\n",
      "based Revenue could feel the squeeze but\n",
      "intentionally dampening investor\n",
      "enthusiasm the release of deep SE R1 is\n",
      "open source software also democratizes\n",
      "access to powerful AI capabilities\n",
      "companies and governments around the\n",
      "world can build upon its foundation\n",
      "without the licensing fears or the\n",
      "restrictions imposed by us firms this\n",
      "could accelerate AI adoption globally\n",
      "but reduce demand for us developed\n",
      "models impacting revenue streams for\n",
      "firms like open Ai and Google cloud in\n",
      "the stock market companies heavily\n",
      "reliant on AI licensing Cloud\n",
      "infrastructure and invidious chips or\n",
      "API Integrations could face downward\n",
      "pressure as investors factor in lower\n",
      "projected growth or increased\n",
      "competition now in the intro I made a\n",
      "little side reference to the potential\n",
      "of a scop angle and while I'm not much\n",
      "of a conspiracy theorist myself some\n",
      "have argued that perhaps we should not\n",
      "take the Chinese at their word when it\n",
      "comes to how the model was produced if\n",
      "it really was produced on second tier\n",
      "hardware for just a few million dollars\n",
      "it's major but some argue that perhaps\n",
      "China invested heavily at the state\n",
      "level to assist hoping to upset the\n",
      "status quo in America by by making what\n",
      "is supposed to be very hard look\n",
      "supposedly cheap and easy but only time\n",
      "will tell so that's deep seek R1 in a\n",
      "nutshell a scrappy little AI punching\n",
      "above its weight built using clever\n",
      "techniques and designed to make advanced\n",
      "AI accessible to more people than ever\n",
      "before it's not perfect it's not trying\n",
      "to be but it's a fascinating glimpse\n",
      "into what the future of AI might look\n",
      "like lightweight efficient and a little\n",
      "rough around the edges but full of\n",
      "potential now if you found this little\n",
      "explainer on deep seek to be any\n",
      "combination of informative or\n",
      "entertaining remember that I'm mostly in\n",
      "this for the subs and likes so I'd be\n",
      "honored if you consider subscribing to\n",
      "my channel to get more like it and\n",
      "there's also a share button down in the\n",
      "bottom here so somewhere in your toolbar\n",
      "there'll be a forward icon which you can\n",
      "use to click on to send this to somebody\n",
      "else that you think probably wants to be\n",
      "educated and just doesn't know about\n",
      "this channel so if you want to tell them\n",
      "about deep SE car1 send them a link to\n",
      "this video if you have any interest in\n",
      "matters related to the autism spectrum\n",
      "check out the free sample of my book on\n",
      "Amazon it's everything I know now about\n",
      "living your best life on the spectrum\n",
      "that I wish I'd known long ago in the\n",
      "meantime and in between time hope to see\n",
      "you next time right right here in Dave's\n",
      "Garage do it l do it do it\n",
      "\n",
      "Transcript saved as youtube_transcript.txt.\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Function to extract the video ID from a full YouTube URL\n",
    "def get_video_id(youtube_url):\n",
    "    if \"watch?v=\" in youtube_url:\n",
    "        return youtube_url.split(\"watch?v=\")[1].split(\"&\")[0]\n",
    "    elif \"youtu.be/\" in youtube_url:\n",
    "        return youtube_url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL format.\")\n",
    "\n",
    "# Enter the YouTube video URL\n",
    "youtube_url = target_video\n",
    "\n",
    "try:\n",
    "    # Get the video ID\n",
    "    video_id = get_video_id(youtube_url)\n",
    "\n",
    "    # Fetch the transcript\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "    # Combine the transcript into plain text\n",
    "    plain_text_transcript = \"\\n\".join([entry['text'] for entry in transcript])\n",
    "\n",
    "    # Display the plain text transcript\n",
    "    print(plain_text_transcript)\n",
    "\n",
    "    # Optionally, save the plain text to a file\n",
    "    with open(\"youtube_transcript.txt\", \"w\") as f:\n",
    "        f.write(plain_text_transcript)\n",
    "        \n",
    "    print(\"\\nTranscript saved as youtube_transcript.txt.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a711ab-4152-46df-9bfc-9de49c52dd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
